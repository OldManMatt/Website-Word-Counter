# Website-Word-Counter
Finds and ranks the most commonly used words on a website.

This program is pretty self explanitory, but complete_website_finder.py is a module that finds most of the relevant pages in a website. It does this by iterating through all of the links in the url provided, and checking if those links branch off from the first link. If they do branch off, then the link is added to the list_of_links list. Then, no matter if it did or did not branch off, the program then iterates over the links within THIS link, and continues to search for pages within the first url. Again, if the program recognizes one of these links as a page of the first url, then it is added to the list.
Then, the program organizes the links into a set to remove any duplicates, and returnes the set.

The website_words.py file is the file that actually finds the words within all of the links provided by complete_website_finder.py. The user inputs the url they want to target, and the program ranks and prints out all of the words it found. The ignore_words list contains all of the common words the program shoudl rank seperately, like the, and, or, of, ect. This way, the program focuses on ranking the important words. Below this list, there are three other empty lists: list_of_words, list_of_ignored_words, and list_of_lines. list_of_words contains all of the words found on the website, excluding the ignored words. list_of_ignored_words stores the words in the website that ARE in the ignore_words list. list_of_lines keeps track of all of the lines that have already been accounted for, becuase the program was having issues with counting the words on a line over and over.
After all of these lists have been declared, the program iterates over the links provided by get_links(), and searches for all of the 'p' paragraph tags in the .html document. The program then iterates over the the individual paragraphs, and checks to see if the line has already been read. If the line hasn't been read, the it is added to list_of_lines, and is split into individual words. Then, it iterates over the individual words, and either adds it to list_of_words or list_of_ignored_words depending on whether or not the word is present in the ignore_words list.
Next, the program ranks all of the words it found from most common to least common. It creates a set of list_of_words to remove any duplicates. Then, it creates the words_ranked_tuples list to store the word and the number of times it was used. Again, the program iterates over the set and creates tuples where the first item is the word, and the second item is the number of times it was used. After this is completed, it ranks all of the tuples from most common to least common. The program does the same thing for list_of_ignored_words.
Finally, the program prints each of the lists of tuples.
